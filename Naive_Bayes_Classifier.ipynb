{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07207cdc",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0337b1",
   "metadata": {},
   "source": [
    "The Naive Bayes classifier is a popular probabilistic machine learning algorithm used for classification tasks, particularly in text classification and spam email detection. It's based on Bayes' theorem and assumes that features (independent variables) are conditionally independent of each other given the class label. Despite its \"naive\" assumption of independence, it often performs surprisingly well and is computationally efficient. The classifier calculates the probability of an input belonging to each class and selects the class with the highest probability as the prediction.\n",
    "\n",
    "![Naive Bayes Classifier](https://miro.medium.com/v2/resize:fit:600/1*aFhOj7TdBIZir4keHMgHOw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6614a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for the code\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a1ee23",
   "metadata": {},
   "source": [
    "## Dataset used for testing the model\n",
    "\n",
    "The dataset used for testing the model is a standard dataset known as IRIS dataset.  \n",
    "The dataset can be found [here](https://archive.ics.uci.edu/dataset/53/iris) or in the my [Github Repository](https://github.com/Aditya-0911/Naive-Bayes-Classifier)\n",
    "\n",
    "The Iris dataset is a renowned and extensively used dataset in the realms of machine learning and statistics. It was introduced by the British biologist and statistician Ronald A. Fisher in 1936. This dataset has become a cornerstone in the field, serving as a benchmark for various classification and clustering tasks. It stands as a fundamental resource for both students and researchers in the domains of data science and machine learning.\n",
    "\n",
    "**Key Characteristics of the Iris Dataset:**\n",
    "\n",
    "- **Dataset Type:** The Iris dataset is classified as a multivariate dataset, signifying that it contains measurements of multiple features or attributes for each individual sample.\n",
    "\n",
    "- **Number of Classes:** The dataset encompasses three distinct classes, each representing a species of iris flowers: Setosa, Versicolor, and Virginica.\n",
    "\n",
    "- **Features:** For each sample of an iris flower, the dataset includes four essential features: sepal length, sepal width, petal length, and petal width. These measurements are recorded in centimeters.\n",
    "\n",
    "- **Sample Size:** The Iris dataset comprises a total of 150 samples, with an equal distribution of 50 samples for each of the three classes.\n",
    "\n",
    "The Iris dataset's enduring significance lies in its simplicity and well-defined classes, making it an invaluable starting point for exploring various aspects of data analysis, preprocessing, and machine learning. It continues to be a timeless resource, aiding in the understanding of more complex datasets and machine learning challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa82cb5",
   "metadata": {},
   "source": [
    "## Code Explanation\n",
    "\n",
    "The provided Python code implements a Naive Bayes classifier for classification tasks using a user-defined dataset. Here's how it works:\n",
    "\n",
    "1. The user inputs the filename of a CSV dataset and specifies the target variable (class label).\n",
    "\n",
    "2. The script extracts the target variable values and allows the user to select a subset of columns (factors) to use as features for classification.\n",
    "\n",
    "3. It splits the dataset into training and testing sets (80% training and 20% testing).\n",
    "\n",
    "4. The Naive Bayes classifier is applied to the training dataset using a normal distribution probability function. It calculates the prior probabilities, likelihoods, and posterior probabilities for each class.\n",
    "\n",
    "5. The script classifies the data points in the testing dataset and calculates the accuracy of the classification.\n",
    "\n",
    "6. The accuracy of the Naive Bayes classifier is printed for both the training and testing datasets.\n",
    "\n",
    "This code provides a basic implementation of a Naive Bayes classifier for educational purposes. For more advanced applications, consider using specialized libraries like scikit-learn, which offer a wide range of machine learning algorithms and additional features for model evaluation and tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67f0191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your file name: iris.csv\n",
      "Columns in the dataframe are: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
      "Enter your target name: species\n",
      "Select the factors (features):\n",
      "Enter the number in front of column names:\n",
      "0  -  sepal_length\n",
      "1  -  sepal_width\n",
      "2  -  petal_length\n",
      "3  -  petal_width\n",
      "4  -  species\n",
      "Enter the numbers: 0:3\n",
      "Naive Bayes accuracy for the training dataset: 0.95\n",
      "Naive Bayes accuracy for the testing dataset: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Define a function for the Naive Bayes classifier\n",
    "def devdas(df, y, inp):\n",
    "    # Extract the target variable values\n",
    "    a = df[y].to_list()\n",
    "    \n",
    "    # Check if the input specifies a range or a list of factors\n",
    "    dec = ':'\n",
    "    factor = []\n",
    "    if dec in inp:\n",
    "        # If the input contains a range (e.g., \"0:5\"), extract columns within the specified range\n",
    "        x = inp.split(':')\n",
    "        for i in range(int(x[0]), int(x[1]) + 1):\n",
    "            factor.append(fac[i])\n",
    "    else:\n",
    "        # If the input contains a comma-separated list (e.g., \"0,1,3,5\"), extract specified columns\n",
    "        x = inp.split(',')\n",
    "        for i in x:\n",
    "            factor.append(fac[int(i)])\n",
    "    \n",
    "    # Include the target variable in the list of factors\n",
    "    factor.append(y)\n",
    "    \n",
    "    # Select the relevant columns from the DataFrame\n",
    "    df = df[factor]\n",
    "    \n",
    "    # Sort the columns to ensure consistent order\n",
    "    df = df.sort_index(axis=1)\n",
    "    \n",
    "    # Get the column names and calculate mean and standard deviation\n",
    "    cols = list(df.columns)\n",
    "    mean = df.pivot_table(index=y, values=cols, aggfunc=np.mean)\n",
    "    std = df.pivot_table(index=y, values=cols, aggfunc=np.std)\n",
    "    std = std.to_numpy()\n",
    "    mean = mean.to_numpy()\n",
    "    p = m.pi\n",
    "    e = m.e\n",
    "    \n",
    "    # Define a function to calculate the normal distribution probability\n",
    "    def normdist(x, m1, s1):\n",
    "        k = 1 / ((pow(2 * p, 0.5)) * s1)\n",
    "        prob = k * pow(e, -0.5 * pow((x - m1) / (s1), 2))\n",
    "        return prob\n",
    "    \n",
    "    # Calculate the frequency of each class in the target variable\n",
    "    f = dict()\n",
    "    for i in range(len(a)):\n",
    "        if a[i] in f:\n",
    "            f[a[i]] += 1\n",
    "        else:\n",
    "            f[a[i]] = 1\n",
    "    \n",
    "    keys = list(f.keys())\n",
    "    val = list(f.values())\n",
    "    \n",
    "    # Normalize class frequencies\n",
    "    val = np.array(val)\n",
    "    val = val / len(df)\n",
    "    f = dict(zip(keys, val))\n",
    "    \n",
    "    # Calculate prior probabilities\n",
    "    p1 = list(f.values())\n",
    "    f = dict(sorted(f.items()))\n",
    "    keys = list(f.keys())\n",
    "    \n",
    "    # Remove the target variable column from the DataFrame\n",
    "    df.drop(y, axis=1, inplace=True)\n",
    "    cols = list(df.columns)\n",
    "    \n",
    "    # Classify data for each class\n",
    "    for w in keys:\n",
    "        pro = []\n",
    "        for i in range(len(df)):\n",
    "            l = df.iloc[i].to_list()\n",
    "            temp = 1\n",
    "            for j in range(len(cols)):\n",
    "                temp *= normdist(l[j], mean[keys.index(w), j], std[keys.index(w), j])\n",
    "            pro.append(temp)\n",
    "        pro = np.array(pro)\n",
    "        pro = list(pro * f[w])\n",
    "        df[w] = pro\n",
    "    \n",
    "    # Determine the predicted class for each data point\n",
    "    m1 = []\n",
    "    for i in range(len(df)):\n",
    "        l = df.iloc[i].to_list()[len(cols):len(df.columns)]\n",
    "        test = max(l)\n",
    "        index = l.index(test)\n",
    "        m1.append(keys[index])\n",
    "    \n",
    "    # Calculate and return accuracy\n",
    "    count = 0\n",
    "    for i in range(len(df)):\n",
    "        if m1[i] == a[i]:\n",
    "            count += 1\n",
    "    return count / len(df)\n",
    "\n",
    "# Input filename from the user\n",
    "x = input(\"Enter your file name: \")\n",
    "\n",
    "# Read data from the CSV file into a DataFrame\n",
    "df = pd.read_csv(x)\n",
    "\n",
    "# Get the column names\n",
    "fac = list(df.columns)\n",
    "print('Columns in the dataframe are:', fac)\n",
    "\n",
    "# Input the target variable\n",
    "y = input(\"Enter your target name: \")\n",
    "\n",
    "# Select factors (features) for analysis\n",
    "print('Select the factors (features):')\n",
    "print('Enter the number in front of column names:')\n",
    "for i in range(len(fac)):\n",
    "    print(i, ' - ', fac[i])\n",
    "\n",
    "inp = input('Enter the numbers: ')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train = df.sample(frac=0.80)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "# Apply the Naive Bayes classifier to training and testing datasets\n",
    "trainp = devdas(train, y, inp)\n",
    "testp = devdas(test, y, inp)\n",
    "\n",
    "# Display accuracy for training and testing datasets\n",
    "print(\"Naive Bayes accuracy for the training dataset:\", trainp)\n",
    "print(\"Naive Bayes accuracy for the testing dataset:\", testp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7124fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the train and test dataset into x_train,y_train and x_test,y_test\n",
    "y_train=train.species.to_numpy()\n",
    "x_train=train.drop('species',axis=1).to_numpy()\n",
    "y_test=test.species.to_numpy()\n",
    "x_test=test.drop('species',axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2337ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn library to verify our values\n",
    "\n",
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61ef4052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy for train dataset using sklearn:  0.95\n"
     ]
    }
   ],
   "source": [
    "# the accuracy from sklearn and our model are comming same\n",
    "nb.fit(x_train,y_train)\n",
    "print('Naive Bayes accuracy for train dataset using sklearn: ',nb.score(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6847616b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy for test dataset using sklearn:  1.0\n"
     ]
    }
   ],
   "source": [
    "nb.fit(x_test,y_test)\n",
    "print('Naive Bayes accuracy for test dataset using sklearn: ',nb.score(x_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
